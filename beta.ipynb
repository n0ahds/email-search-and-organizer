{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "# Machine Learning Lib\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.callbacks import LambdaCallback\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dropout, Dense, Flatten, Activation\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, OrdinalEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pd' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m#Load the CSV file as a dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m dataset_train \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mmessages_train.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m dataset_test \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mread_csv(\u001b[39m\"\u001b[39m\u001b[39mmessages_test.csv\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m      5\u001b[0m dataset_train\u001b[39m.\u001b[39mhead()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'pd' is not defined"
     ]
    }
   ],
   "source": [
    "#Load the CSV file as a dataframe\n",
    "dataset_train = pd.read_csv(\"messages_train.csv\")\n",
    "dataset_test = pd.read_csv(\"messages_test.csv\")\n",
    "\n",
    "dataset_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dataset_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Extract the features and the target from the dataframe\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m x_train \u001b[39m=\u001b[39m dataset_train\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      3\u001b[0m x_test \u001b[39m=\u001b[39m dataset_test\u001b[39m.\u001b[39miloc[:, :\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n\u001b[0;32m      5\u001b[0m y_train \u001b[39m=\u001b[39m dataset_train\u001b[39m.\u001b[39miloc[:, \u001b[39m-\u001b[39m\u001b[39m1\u001b[39m]\u001b[39m.\u001b[39mvalues\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dataset_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Extract the features and the target from the dataframe\n",
    "x_train = dataset_train.iloc[:, :-1].values\n",
    "x_test = dataset_test.iloc[:, :-1].values\n",
    "\n",
    "y_train = dataset_train.iloc[:, -1].values\n",
    "y_test = dataset_test.iloc[:, -1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'OneHotEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[3], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Create a column transformer\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m ct \u001b[39m=\u001b[39m OneHotEncoder(sparse\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m, handle_unknown\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mignore\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      4\u001b[0m \u001b[39m# Fit and transform the data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m x_train \u001b[39m=\u001b[39m ct\u001b[39m.\u001b[39mfit_transform(x_train)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'OneHotEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Create a column transformer\n",
    "ct = OneHotEncoder(sparse=False, handle_unknown='ignore')\n",
    "\n",
    "# Fit and transform the data\n",
    "x_train = ct.fit_transform(x_train)\n",
    "x_test = ct.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LabelEncoder' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Encode the target\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m le \u001b[39m=\u001b[39m LabelEncoder()\n\u001b[0;32m      4\u001b[0m y_train \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mfit_transform(y_train)\n\u001b[0;32m      5\u001b[0m y_test \u001b[39m=\u001b[39m le\u001b[39m.\u001b[39mtransform(y_test)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'LabelEncoder' is not defined"
     ]
    }
   ],
   "source": [
    "# Encode the target\n",
    "le = LabelEncoder()\n",
    "\n",
    "y_train = le.fit_transform(y_train)\n",
    "y_test = le.transform(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[5], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Convert labels to categorical variables\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m num_classes \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(np\u001b[39m.\u001b[39munique(y_train))\n\u001b[0;32m      4\u001b[0m y_train \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_train, num_classes)\n\u001b[0;32m      5\u001b[0m y_test \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39mto_categorical(y_test, num_classes)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "# Convert labels to categorical variables\n",
    "num_classes = len(np.unique(y_train))\n",
    "\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = tf.keras.utils.to_categorical(y_test, num_classes)\n",
    "\n",
    "x_train.shape, x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'x_train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39m# Define some variables\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m max_input \u001b[39m=\u001b[39m x_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]\n\u001b[0;32m      3\u001b[0m batch_size \u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m      4\u001b[0m epochs \u001b[39m=\u001b[39m \u001b[39m5\u001b[39m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'x_train' is not defined"
     ]
    }
   ],
   "source": [
    "# Define some variables\n",
    "max_input = x_train.shape[1]\n",
    "batch_size = 1\n",
    "epochs = 5\n",
    "plot = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Dropout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate_network\u001b[39m(n_dense\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m      2\u001b[0m                    dense_units\u001b[39m=\u001b[39m\u001b[39m6\u001b[39m,\n\u001b[0;32m      3\u001b[0m                    activation\u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m----> 4\u001b[0m                    dropout\u001b[39m=\u001b[39mDropout,\n\u001b[0;32m      5\u001b[0m                    dropout_rate\u001b[39m=\u001b[39m\u001b[39m0.1\u001b[39m,\n\u001b[0;32m      6\u001b[0m                    kernel_initializer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mglorot_uniform\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      7\u001b[0m                    optimizer\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39madam\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m      8\u001b[0m                    num_classes\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m,\n\u001b[0;32m      9\u001b[0m                    max_input\u001b[39m=\u001b[39mx_train\u001b[39m.\u001b[39mshape[\u001b[39m1\u001b[39m]):\n\u001b[0;32m     10\u001b[0m       \u001b[39m# Layer 1\u001b[39;00m\n\u001b[0;32m     11\u001b[0m       model \u001b[39m=\u001b[39m Sequential()\n\u001b[0;32m     12\u001b[0m       model\u001b[39m.\u001b[39madd(Dense(dense_units, input_shape\u001b[39m=\u001b[39m(max_input,),\n\u001b[0;32m     13\u001b[0m                       kernel_initializer\u001b[39m=\u001b[39mkernel_initializer))\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Dropout' is not defined"
     ]
    }
   ],
   "source": [
    "def create_network(n_dense=1,\n",
    "                   dense_units=6,\n",
    "                   activation= 'relu',\n",
    "                   dropout=Dropout,\n",
    "                   dropout_rate=0.1,\n",
    "                   kernel_initializer='glorot_uniform',\n",
    "                   optimizer='adam',\n",
    "                   num_classes=1,\n",
    "                   max_input=x_train.shape[1]):\n",
    "      # Layer 1\n",
    "      model = Sequential()\n",
    "      model.add(Dense(dense_units, input_shape=(max_input,),\n",
    "                      kernel_initializer=kernel_initializer))\n",
    "      model.add(Activation(activation))\n",
    "      model.add(dropout(dropout_rate))\n",
    "\n",
    "      # Layer 2 to n-1\n",
    "      for i in range(n_dense - 1):\n",
    "          model.add(Dense(dense_units, kernel_initializer=kernel_initializer))\n",
    "          model.add(Activation(activation))\n",
    "          model.add(dropout(dropout_rate))\n",
    "\n",
    "      # Layer n\n",
    "      model.add(Dense(num_classes))\n",
    "      model.add(Activation('softmax'))\n",
    "      model.compile(loss='categorical_crossentropy',\n",
    "                    optimizer=optimizer,\n",
    "                    metrics=['accuracy'])\n",
    "      return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overide any of the hyperparameters\n",
    "network = {\n",
    "    'n_dense': 5,\n",
    "    'dense_units': 10,\n",
    "    # 'optimizer': 'Adamax'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model Complete.\n",
      "\n",
      "Building network 1 - Basic IDS...\n",
      "Epoch 1/5\n",
      "1125/1125 [==============================] - 1s 803us/step - loss: 0.6945 - accuracy: 0.5333 - val_loss: 0.6961 - val_accuracy: 0.4262\n",
      "Epoch 2/5\n",
      "1125/1125 [==============================] - 1s 687us/step - loss: 0.6768 - accuracy: 0.5956 - val_loss: 0.7204 - val_accuracy: 0.4262\n",
      "Epoch 3/5\n",
      "1125/1125 [==============================] - 1s 673us/step - loss: 0.4753 - accuracy: 0.8053 - val_loss: 1.0149 - val_accuracy: 0.4098\n",
      "Epoch 4/5\n",
      "1125/1125 [==============================] - 1s 676us/step - loss: 0.2283 - accuracy: 0.9253 - val_loss: 1.3759 - val_accuracy: 0.4590\n",
      "Epoch 5/5\n",
      "1125/1125 [==============================] - 1s 686us/step - loss: 0.1133 - accuracy: 0.9662 - val_loss: 1.5435 - val_accuracy: 0.5410\n",
      "61/61 [==============================] - 0s 517us/step - loss: 1.5435 - accuracy: 0.5410\n",
      "\n",
      "Network 1 - Basic IDS results\n",
      "Hyperparameters: {'n_dense': 5, 'dense_units': 10}\n",
      "Test score: 1.5434712171554565\n",
      "Test accuracy: 0.5409836173057556\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nModel Complete.\")\n",
    "\n",
    "print('\\nBuilding network 1 - Basic IDS...')\n",
    "\n",
    "model = create_network(num_classes=num_classes, **network)\n",
    "history_model = model.fit(x_train,\n",
    "                            y_train,\n",
    "                            batch_size=batch_size,\n",
    "                            epochs=epochs,\n",
    "                            verbose=1,\n",
    "                            validation_data=(x_test,y_test),\n",
    "                            validation_split=0.1)\n",
    "\n",
    "score_model = model.evaluate(x_test,\n",
    "                               y_test,\n",
    "                               batch_size=batch_size,\n",
    "                               verbose=1)\n",
    "\n",
    "\n",
    "\n",
    "print('\\nNetwork 1 - Basic IDS results')\n",
    "print('Hyperparameters:', network)\n",
    "print('Test score:', score_model[0])\n",
    "print('Test accuracy:', score_model[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "[1 1 1 0 0 1 1 0 0 1 1 1 0 0 1 1 0 0 1 0 0 0 0 1 1 1 0 0 1 1 0 1 1 0 0 1 1\n",
      " 1 1 1 0 0 0 0 1 0 1 1 1 0 1 0 1 1 1 1 1 0 1 0 1] [1 1 1 1 1 1 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0\n",
      " 1 1 0 0 0 1 1 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "# Prediction Engine\n",
    "y_true = np.argmax(y_test, axis=1) \n",
    "y_pred = np.argmax(model.predict(x_test), axis=1)\n",
    "print(y_true, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Calculating the prediction accuracy ...\n",
      "\n",
      "Test accuracy of Model: 54.09836065573771%\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nCalculating the prediction accuracy ...\")\n",
    "acc = np.sum(y_pred == y_true) / y_test.shape[0]\n",
    "print(\"\\nTest accuracy of Model: {}%\".format(acc * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the confusion matrix ...\n",
      "[[18  8]\n",
      " [20 15]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating the confusion matrix ...\")\n",
    "cm = confusion_matrix(y_true, y_pred)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating the classification report ...\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.47      0.69      0.56        26\n",
      "           1       0.65      0.43      0.52        35\n",
      "\n",
      "    accuracy                           0.54        61\n",
      "   macro avg       0.56      0.56      0.54        61\n",
      "weighted avg       0.58      0.54      0.54        61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Generating the classification report ...\")\n",
    "cr = classification_report(y_true, y_pred)\n",
    "print(cr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Output Classes in Test Dataset\n",
      "spam\n",
      "1    35\n",
      "0    26\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nOutput Classes in Test Dataset\\n{}\".format(dataset_test['spam'].value_counts()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the model\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32, # Take 32 at a time\n",
    "          epochs=5,\n",
    "          validation_data=(x_test,y_test))\n",
    "\n",
    "model.evaluate(x=x_test, y=y_test, verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate the perturbation \n",
    "def adversarial_pattern(traffic, label):\n",
    "\n",
    "  traffic = tf.cast(traffic, tf.float32) # Convert traffic into tensor\n",
    "\n",
    "  with tf.GradientTape() as tape: # Initating gradients\n",
    "    tape.watch(traffic)\n",
    "    prediction = model(traffic)\n",
    "    loss = tf.keras.losses.MSE(label, prediction)\n",
    "\n",
    "  gradient = tape.gradient(loss, traffic)\n",
    "  signed_gradient =tf.sign(gradient)\n",
    "\n",
    "  return signed_gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to generate the adversarial sample\n",
    "def generate_adversarials(batch_size):\n",
    "  while True:\n",
    "    x=[]\n",
    "    y=[]\n",
    "    for batch in range (batch_size):\n",
    "      N = random.randint(0, 100)\n",
    "\n",
    "      label = y_train[N]\n",
    "      traffic = x_train[N]\n",
    "\n",
    "      perturbations = adversarial_pattern(traffic.reshape(1, x_train.shape[1]), label).numpy() # Creates the noise in the traffic\n",
    "\n",
    "      epsilon = 0.1  # Reduce the effect of the perturbations (0.1 is the standard)\n",
    "      adversarial = traffic + perturbations * epsilon\n",
    "\n",
    "      x.append(adversarial)\n",
    "      y.append(y_train[N])\n",
    "\n",
    "    x = np.asarray(x).reshape(batch_size, traffic.shape[0])\n",
    "    y = np.asarray(y)\n",
    "\n",
    "    yield x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 10 adversarial samples\n",
    "x_test_adv, y_test_adv = next(generate_adversarials(32))\n",
    "\n",
    "[print('Base accuracy on Adversarial traffic:', model.evaluate(x=x_test_adv, y=y_test_adv, verbose=0), \"\\n\")]\n",
    "\n",
    "print(x_test_adv[0])\n",
    "\n",
    "plt.axis('off')\n",
    "plt.imshow(x_test_adv[0].reshape(2, int(x_train.shape[1]/2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original traffic visualization\n",
    "print(\"Original Traffic, selected at random\")\n",
    "\n",
    "for i in range(5):\n",
    "    plt.axis('off')\n",
    "    plt.imshow(x_train[random.randint(0, len(x_train))].reshape(2, int(x_train.shape[1]/2)))\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
